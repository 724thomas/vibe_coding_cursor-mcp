import requests
import re
import time
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ScrapingResult:
    """ìŠ¤í¬ë˜í•‘ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    price: str
    url: str
    source: str
    description: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "name": self.name,
            "price": self.price,
            "url": self.url,
            "source": self.source,
            "description": self.description
        }


class WebScraper:
    """ì›¹ í¬ë¡¤ë§ì„ í†µí•œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        """ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”"""
        self.session = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        self.session.headers.update(self.headers)
        
        # ì£¼ìš” ì‡¼í•‘ëª° ê²€ìƒ‰ URL íŒ¨í„´
        self.search_urls = {
            "ì¿ íŒ¡": "https://www.coupang.com/np/search?q={}",
            "11ë²ˆê°€": "https://search.11st.co.kr/Search.tmall?method=getTotalSearchSeller&isGnb=Y&keyword={}",
            "Gë§ˆì¼“": "http://browse.gmarket.co.kr/search?keyword={}",
            "ì˜¥ì…˜": "http://itemsearch.auction.co.kr/search?keyword={}",
            "ì¸í„°íŒŒí¬": "http://shopping.interpark.com/search.do?keyword={}"
        }
    
    def fetch_page(self, url: str) -> Optional[str]:
        """ì›¹ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        try:
            logger.info(f"í˜ì´ì§€ ìš”ì²­ ì‹œì‘: {url}")
            response = self.session.get(url, timeout=5)  # íƒ€ì„ì•„ì›ƒì„ 5ì´ˆë¡œ ë‹¨ì¶•
            response.raise_for_status()
            
            # ì¸ì½”ë”© ì„¤ì •
            if response.encoding:
                response.encoding = response.apparent_encoding
            
            logger.info(f"í˜ì´ì§€ ìš”ì²­ ì„±ê³µ: {url}")
            return response.text
            
        except requests.RequestException as e:
            logger.error(f"í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {url}: {e}")
            return None
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {url}: {e}")
            return None
    
    def extract_product_info(self, html_content: str, base_url: str = "") -> List[ScrapingResult]:
        """HTMLì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        if not html_content:
            return []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            products = []
            
            # ë‹¤ì–‘í•œ ìƒí’ˆ ì •ë³´ ì„ íƒì íŒ¨í„´
            product_selectors = [
                # ì¼ë°˜ì ì¸ ìƒí’ˆ ì»¨í…Œì´ë„ˆ
                {'container': '.product', 'name': 'h2, h3, .product-name', 'price': '.price, .product-price', 'link': 'a'},
                {'container': '.product-item', 'name': 'h2, h3, .title', 'price': '.price, .cost', 'link': 'a'},
                {'container': '.item', 'name': '.name, .title, h3', 'price': '.price, .cost', 'link': 'a'},
                {'container': '.goods', 'name': '.goods-name, h3', 'price': '.price, .cost', 'link': 'a'},
                
                # ì¿ íŒ¡ ìŠ¤íƒ€ì¼
                {'container': '.search-product', 'name': '.name', 'price': '.price-value', 'link': 'a'},
                
                # 11ë²ˆê°€ ìŠ¤íƒ€ì¼  
                {'container': '.c_prd_item', 'name': '.prd_name', 'price': '.price_real', 'link': 'a'},
                
                # Gë§ˆì¼“ ìŠ¤íƒ€ì¼
                {'container': '.box__item-container', 'name': '.text__item', 'price': '.text_price', 'link': 'a'},
                
                # ì¼ë°˜ì ì¸ ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ
                {'container': 'li', 'name': 'h2, h3, .title, .name', 'price': '.price, .cost', 'link': 'a'},
                {'container': '.list-item', 'name': '.title, .name', 'price': '.price', 'link': 'a'}
            ]
            
            # ê° ì„ íƒì íŒ¨í„´ìœ¼ë¡œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œë„
            for selector_config in product_selectors:
                containers = soup.select(selector_config['container'])
                
                for container in containers[:10]:  # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ
                    try:
                        product_info = self._extract_single_product(container, selector_config, base_url)
                        if product_info and product_info.name and product_info.price:
                            products.append(product_info)
                    except Exception as e:
                        logger.debug(f"ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                        continue
                
                # ìƒí’ˆì„ ì°¾ì•˜ìœ¼ë©´ ë‹¤ë¥¸ íŒ¨í„´ì€ ì‹œë„í•˜ì§€ ì•ŠìŒ
                if products:
                    break
            
            return products[:5]  # ìµœëŒ€ 5ê°œ ê²°ê³¼ë§Œ ë°˜í™˜
            
        except Exception as e:
            logger.error(f"HTML íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_single_product(self, container, selector_config: Dict[str, str], base_url: str) -> Optional[ScrapingResult]:
        """ë‹¨ì¼ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            # ìƒí’ˆëª… ì¶”ì¶œ
            name_element = container.select_one(selector_config['name'])
            if not name_element:
                return None
            
            name = name_element.get_text(strip=True)
            if not name or len(name) < 2:
                return None
            
            # ê°€ê²© ì¶”ì¶œ ê°œì„ 
            price_element = container.select_one(selector_config['price'])
            if not price_element:
                # ê°€ê²©ì´ ì—†ëŠ” ê²½ìš° ë‹¤ë¥¸ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
                price_patterns = [
                    '.price', '.cost', '.amount', '[class*="price"]', '[class*="cost"]',
                    '.sale-price', '.final-price', '.current-price', '.product-price',
                    '[data-price]', '.price-now', '.price-real', '.price-value'
                ]
                for pattern in price_patterns:
                    price_element = container.select_one(pattern)
                    if price_element:
                        break
            
            price = "ê°€ê²© ì •ë³´ ì—†ìŒ"
            price_numeric = 0
            if price_element:
                price_text = price_element.get_text(strip=True)
                # ê°€ê²©ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ì„ ìœ„í•œ ìˆ«ìê°’ë„ ì €ì¥
                price_numbers = re.findall(r'[\d,]+', price_text)
                if price_numbers:
                    # ê°€ì¥ í° ìˆ«ìë¥¼ ê°€ê²©ìœ¼ë¡œ ì„ íƒ (í• ì¸ê°€ê°€ ì•„ë‹Œ ì •ê°€ë¥¼ í”¼í•˜ê¸° ìœ„í•´)
                    numeric_values = [int(p.replace(',', '')) for p in price_numbers if len(p.replace(',', '')) >= 3]
                    if numeric_values:
                        price_numeric = min(numeric_values)  # ìµœì†Œê°’ì„ ì‹¤ì œ íŒë§¤ê°€ë¡œ ì¶”ì •
                        price = f"{price_numeric:,}ì›"
                elif re.search(r'\d', price_text):
                    price = price_text
            
            # ë§í¬ ì¶”ì¶œ
            link_element = container.select_one(selector_config['link'])
            url = ""
            if link_element and link_element.get('href'):
                href = link_element.get('href')
                if href.startswith('http'):
                    url = href
                elif base_url:
                    url = urljoin(base_url, href)
            
            # ì„¤ëª… ì¶”ì¶œ (ì„ íƒì‚¬í•­)
            description = ""
            desc_selectors = ['.description', '.summary', '.spec']
            for desc_sel in desc_selectors:
                desc_elem = container.select_one(desc_sel)
                if desc_elem:
                    description = desc_elem.get_text(strip=True)[:100]  # ìµœëŒ€ 100ì
                    break
            
            # ì†ŒìŠ¤ íŒë‹¨
            source = "ì˜¨ë¼ì¸ì‡¼í•‘ëª°"
            if base_url:
                parsed_url = urlparse(base_url)
                domain = parsed_url.netloc.lower()
                if 'coupang' in domain:
                    source = "ì¿ íŒ¡"
                elif '11st' in domain:
                    source = "11ë²ˆê°€"
                elif 'gmarket' in domain:
                    source = "Gë§ˆì¼“"
                elif 'auction' in domain:
                    source = "ì˜¥ì…˜"
                elif 'interpark' in domain:
                    source = "ì¸í„°íŒŒí¬"
            
            result = ScrapingResult(
                name=name,
                price=price,
                url=url,
                source=source,
                description=description
            )
            
            # ê°€ê²© ì •ë ¬ì„ ìœ„í•œ ìˆ«ìê°’ ì €ì¥
            result._price_numeric = price_numeric
            
            return result
            
        except Exception as e:
            logger.debug(f"ë‹¨ì¼ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def search_products(self, query: str, max_results: int = 10) -> List[ScrapingResult]:
        """ìƒí’ˆ ê²€ìƒ‰ ì‹¤í–‰ - ê°€ê²© ë¹„êµ ê°•í™”"""
        if not query or not query.strip():
            return []
        
        all_products = []
        search_query = query.strip()
        
        # ë” ë§ì€ ì‡¼í•‘ëª°ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ê°€ê²© ë¹„êµ
        for source, url_pattern in self.search_urls.items():
            try:
                search_url = url_pattern.format(search_query.replace(' ', '+'))
                logger.info(f"{source}ì—ì„œ ê²€ìƒ‰ ì¤‘: {search_url}")
                
                html_content = self.fetch_page(search_url)
                if html_content:
                    products = self.extract_product_info(html_content, search_url)
                    # ê°€ê²© ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆë§Œ ì¶”ê°€
                    valid_products = [p for p in products if hasattr(p, '_price_numeric') and p._price_numeric > 0]
                    all_products.extend(valid_products)
                
                # ìš”ì²­ ê°„ ë”œë ˆì´
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"{source} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ê³¼ ì •ë¦¬ ë° ì¤‘ë³µ ì œê±° (ìƒí’ˆëª… ê¸°ì¤€)
        unique_products = []
        seen_names = set()
        
        for product in all_products:
            # ìƒí’ˆëª… ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            normalized_name = re.sub(r'[^\wê°€-í£]', '', product.name.lower())
            
            if normalized_name not in seen_names and len(normalized_name) > 2:
                seen_names.add(normalized_name)
                unique_products.append(product)
        
        # ê°€ê²©ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì €ê°€ë¶€í„°)
        unique_products.sort(key=lambda x: getattr(x, '_price_numeric', float('inf')))
        
        return unique_products[:max_results]
    
    def format_search_results(self, products: List[ScrapingResult], query: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì˜ì‚¬ê²°ì • ì§€ì› í˜•íƒœë¡œ í¬ë§·"""
        if not products:
            return f"""
ğŸ” **'{query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.**

ğŸ’¡ **ë¹ ë¥¸ ê²€ìƒ‰ ê°œì„  ë°©ë²•:**
âš¡ **ì¦‰ì‹œ ì‹œë„í•´ë³´ì„¸ìš”:**
- ë” êµ¬ì²´ì ì¸ ìƒí’ˆëª…: "{query} 128GB", "{query} 2024ë…„"
- ë¸Œëœë“œëª… ì¶”ê°€: "ì‚¼ì„± {query}", "ì• í”Œ {query}"
- ì˜ë¬¸/í•œê¸€ ì „í™˜ìœ¼ë¡œ ì¬ê²€ìƒ‰

ğŸƒâ€â™‚ï¸ **5ì´ˆë§Œì— ë‹¤ì‹œ ì°¾ê¸°:**
- í•µì‹¬ í‚¤ì›Œë“œë§Œ ì…ë ¥ (ì˜ˆ: "ì•„ì´í°15", "ê°¤ëŸ­ì‹œS24")
- ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì¬ì‹œë„
            """.strip()
        
        # ê°€ê²© ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆê³¼ ì—†ëŠ” ìƒí’ˆ ë¶„ë¦¬
        products_with_price = [p for p in products if hasattr(p, '_price_numeric') and p._price_numeric > 0]
        products_without_price = [p for p in products if not (hasattr(p, '_price_numeric') and p._price_numeric > 0)]
        
        # ê²°ê³¼ í—¤ë” - í•µì‹¬ ì •ë³´ë¥¼ ìµœìƒë‹¨ì— ë…¸ì¶œ
        result_text = f"ğŸ›’ **'{query}' ê°€ê²© ë¹„êµ ì™„ë£Œ!** (ì´ {len(products)}ê°œ ë°œê²¬)\n\n"
        
        if products_with_price:
            # ì¦‰ì‹œ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í•µì‹¬ ì •ë³´ ê°•ì¡°
            lowest_price = products_with_price[0]
            highest_price = products_with_price[-1] if len(products_with_price) > 1 else lowest_price
            
            # ğŸš€ ì¦‰ì‹œ ê²°ì • ê°€ì´ë“œ
            result_text += "## ğŸš€ **ì¦‰ì‹œ ê²°ì • ê°€ì´ë“œ**\n\n"
            result_text += f"ğŸ’° **ì¶”ì²œ ìµœì €ê°€**: {lowest_price.price} â† **{lowest_price.source}**\n"
            
            if len(products_with_price) > 1:
                price_diff = getattr(highest_price, '_price_numeric', 0) - getattr(lowest_price, '_price_numeric', 0)
                result_text += f"ğŸ’¡ **ì ˆì•½ íš¨ê³¼**: ìµœëŒ€ {price_diff:,}ì› ì ˆì•½ ê°€ëŠ¥!\n"
                
                # í‰ê·  ê°€ê²© ëŒ€ë¹„ ì ˆì•½ ì •ë³´
                prices = [getattr(p, '_price_numeric', 0) for p in products_with_price]
                avg_price = sum(prices) / len(prices)
                savings_vs_avg = avg_price - getattr(lowest_price, '_price_numeric', 0)
                if savings_vs_avg > 0:
                    result_text += f"ğŸ“Š **í‰ê· ê°€ ëŒ€ë¹„**: {savings_vs_avg:,.0f}ì› ì €ë ´\n"
            
            result_text += "\n"
            
            # âš¡ ë¹ ë¥¸ ê°€ê²© ë¹„êµí‘œ - ìŠ¤ìº”í•˜ê¸° ì‰¬ìš´ í˜•íƒœ
            result_text += "## âš¡ **3ì´ˆ ê°€ê²© ë¹„êµ**\n\n"
            
            for i, product in enumerate(products_with_price[:5], 1):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                # ìˆœìœ„ë³„ ì´ëª¨ì§€ì™€ ê°€ê²© ê°•ì¡°
                rank_emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}ìœ„"
                
                # ê°€ê²© ì°¨ì´ í‘œì‹œ (2ìœ„ë¶€í„°)
                price_info = product.price
                if i > 1 and hasattr(product, '_price_numeric') and hasattr(lowest_price, '_price_numeric'):
                    price_diff = product._price_numeric - lowest_price._price_numeric
                    price_info += f" *(+{price_diff:,}ì›)*"
                
                result_text += f"{rank_emoji} **{product.source}**: {price_info}\n"
                
                # ìƒí’ˆëª…ì€ ê°„ë‹¨íˆ í‘œì‹œ
                short_name = product.name[:30] + "..." if len(product.name) > 30 else product.name
                result_text += f"   ğŸ“¦ {short_name}\n\n"
            
            # ğŸ¯ êµ¬ë§¤ ê²°ì • ì§€ì› ì •ë³´
            if len(products_with_price) >= 2:
                result_text += "## ğŸ¯ **êµ¬ë§¤ ê²°ì • ì§€ì›**\n\n"
                
                # ê°€ê²©ëŒ€ë³„ ì¶”ì²œ
                prices = [getattr(p, '_price_numeric', 0) for p in products_with_price]
                min_price = min(prices)
                max_price = max(prices)
                
                # ê°€ê²© ë¶„ì„
                result_text += f"ğŸ’µ **ê°€ê²© ë²”ìœ„**: {min_price:,}ì› ~ {max_price:,}ì›\n"
                
                if len(products_with_price) >= 3:
                    mid_idx = len(products_with_price) // 2
                    mid_product = products_with_price[mid_idx]
                    result_text += f"ğŸ¯ **ì¤‘ê°„ ê°€ê²©ëŒ€**: {mid_product.price} ({mid_product.source})\n"
                
                # ì‡¼í•‘ëª°ë³„ íŠ¹ì§• íŒíŠ¸
                result_text += f"\nğŸ“ **ì‡¼í•‘ íŒ**:\n"
                unique_sources = list(set(p.source for p in products_with_price))
                if "ì¿ íŒ¡" in unique_sources:
                    result_text += "â€¢ ì¿ íŒ¡: ë¡œì¼“ë°°ì†¡ ë¹ ë¥¸ ë°°ì†¡ ê°€ëŠ¥\n"
                if "11ë²ˆê°€" in unique_sources:
                    result_text += "â€¢ 11ë²ˆê°€: í• ì¸ ì¿ í° ë° ì ë¦½ê¸ˆ í˜œíƒ\n"
                if "Gë§ˆì¼“" in unique_sources:
                    result_text += "â€¢ Gë§ˆì¼“: ìŠ¤ë§ˆì¼ì¹´ë“œ ì¶”ê°€ í• ì¸\n"
                
                result_text += "\n"
        
        # ê°€ê²© ì •ë³´ ì—†ëŠ” ìƒí’ˆë“¤ (ê°„ë‹¨íˆ ì²˜ë¦¬)
        if products_without_price:
            result_text += "## ğŸ“‹ **ì¶”ê°€ í™•ì¸ í•„ìš”**\n\n"
            for product in products_without_price[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                result_text += f"â€¢ **{product.name[:40]}...** ({product.source}) - ê°€ê²© í™•ì¸ í•„ìš”\n"
            result_text += "\n"
        
        # ğŸ’¡ ë§ˆì§€ë§‰ êµ¬ë§¤ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
        result_text += "## âœ… **êµ¬ë§¤ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸**\n"
        result_text += "ğŸšš **ë°°ì†¡ë¹„** í¬í•¨ ìµœì¢… ê°€ê²© í™•ì¸\n"
        result_text += "ğŸ·ï¸ **í• ì¸ ì¿ í°** ë° ì ë¦½ê¸ˆ í˜œíƒ í™•ì¸\n"
        result_text += "â­ **íŒë§¤ì í‰ì ** ë° **ìƒí’ˆ ë¦¬ë·°** í™•ì¸\n"
        result_text += "ğŸ›¡ï¸ **A/S ì •ì±…** ë° **êµí™˜/í™˜ë¶ˆ** ì¡°ê±´ í™•ì¸\n\n"
        
        result_text += "âš¡ **5ë¶„ ì•ˆì— ìµœì ì˜ ì„ íƒì„ í•˜ì…¨ìŠµë‹ˆë‹¤!**"
        
        return result_text 